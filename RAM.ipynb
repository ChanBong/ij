{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wx-ZcWW2e-40"
      },
      "source": [
        "## Setup\n",
        "\n",
        "> Follow : https://github.com/xinyu1205/recognize-anything?tab=readme-ov-file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfLWCZhMeyLm",
        "outputId": "ca0382ad-d64d-46b8-fff1-2ad472031b48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Obtaining file:///home/vincent/projects/sprints/ij/recognize-anything\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting clip@ git+https://github.com/openai/CLIP.git (from ram==0.0.1)\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-install-hjk8hp66/clip_81d14f3069a94961ad75364d2d43c4e2\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-install-hjk8hp66/clip_81d14f3069a94961ad75364d2d43c4e2\n",
            "  Resolved https://github.com/openai/CLIP.git to commit a1d071733d7111c9c014f024669f959182114e33\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting timm==0.4.12 (from ram==0.0.1)\n",
            "  Using cached timm-0.4.12-py3-none-any.whl (376 kB)\n",
            "Collecting transformers==4.25.1 (from ram==0.0.1)\n",
            "  Using cached transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "Collecting fairscale==0.4.4 (from ram==0.0.1)\n",
            "  Using cached fairscale-0.4.4.tar.gz (235 kB)\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting pycocoevalcap (from ram==0.0.1)\n",
            "  Downloading pycocoevalcap-1.2-py3-none-any.whl (104.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.3/104.3 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
            "\u001b[?25hCollecting torch (from ram==0.0.1)\n",
            "  Obtaining dependency information for torch from https://files.pythonhosted.org/packages/da/6a/7fb9d82db4568834ff6d4df2fe3b143de4ed65a3f8f93e7daed703626cb6/torch-2.1.2-cp311-cp311-manylinux1_x86_64.whl.metadata\n",
            "  Downloading torch-2.1.2-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Collecting torchvision (from ram==0.0.1)\n",
            "  Obtaining dependency information for torchvision from https://files.pythonhosted.org/packages/6e/c8/cf445dcf86daf1aed298061ad14b8d335fa594596aeaa6b951231328ffd1/torchvision-0.16.2-cp311-cp311-manylinux1_x86_64.whl.metadata\n",
            "  Downloading torchvision-0.16.2-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: Pillow in /home/vincent/miniconda3/envs/hf/lib/python3.11/site-packages (from ram==0.0.1) (10.0.1)\n",
            "Collecting scipy (from ram==0.0.1)\n",
            "  Obtaining dependency information for scipy from https://files.pythonhosted.org/packages/6b/d4/d62ce38ba00dc67d7ec4ec5cc19d36958d8ed70e63778715ad626bcbc796/scipy-1.11.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading scipy-1.11.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /home/vincent/miniconda3/envs/hf/lib/python3.11/site-packages (from transformers==4.25.1->ram==0.0.1) (3.12.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /home/vincent/miniconda3/envs/hf/lib/python3.11/site-packages (from transformers==4.25.1->ram==0.0.1) (0.17.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/vincent/miniconda3/envs/hf/lib/python3.11/site-packages (from transformers==4.25.1->ram==0.0.1) (1.26.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/vincent/miniconda3/envs/hf/lib/python3.11/site-packages (from transformers==4.25.1->ram==0.0.1) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/vincent/miniconda3/envs/hf/lib/python3.11/site-packages (from transformers==4.25.1->ram==0.0.1) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/vincent/miniconda3/envs/hf/lib/python3.11/site-packages (from transformers==4.25.1->ram==0.0.1) (2023.10.3)\n",
            "Requirement already satisfied: requests in /home/vincent/miniconda3/envs/hf/lib/python3.11/site-packages (from transformers==4.25.1->ram==0.0.1) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.25.1->ram==0.0.1)\n",
            "  Downloading tokenizers-0.13.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /home/vincent/miniconda3/envs/hf/lib/python3.11/site-packages (from transformers==4.25.1->ram==0.0.1) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions in /home/vincent/miniconda3/envs/hf/lib/python3.11/site-packages (from torch->ram==0.0.1) (4.7.1)\n",
            "Collecting sympy (from torch->ram==0.0.1)\n",
            "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting networkx (from torch->ram==0.0.1)\n",
            "  Obtaining dependency information for networkx from https://files.pythonhosted.org/packages/d5/f0/8fbc882ca80cf077f1b246c0e3c3465f7f415439bdea6b899f6b19f61f70/networkx-3.2.1-py3-none-any.whl.metadata\n",
            "  Downloading networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: jinja2 in /home/vincent/miniconda3/envs/hf/lib/python3.11/site-packages (from torch->ram==0.0.1) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /home/vincent/miniconda3/envs/hf/lib/python3.11/site-packages (from torch->ram==0.0.1) (2023.9.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->ram==0.0.1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->ram==0.0.1)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->ram==0.0.1)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch->ram==0.0.1)\n",
            "  Obtaining dependency information for nvidia-cudnn-cu12==8.9.2.26 from https://files.pythonhosted.org/packages/ff/74/a2e2be7fb83aaedec84f391f082cf765dfb635e7caa9b49065f73e4835d8/nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->ram==0.0.1)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m957.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:04\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch->ram==0.0.1)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch->ram==0.0.1)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch->ram==0.0.1)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch->ram==0.0.1)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.18.1 (from torch->ram==0.0.1)\n",
            "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:04\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch->ram==0.0.1)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==2.1.0 (from torch->ram==0.0.1)\n",
            "  Obtaining dependency information for triton==2.1.0 from https://files.pythonhosted.org/packages/5c/c1/54fffb2eb13d293d9a429fead3646752ea190de0229bcf3d591ba2481263/triton-2.1.0-0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata\n",
            "  Downloading triton-2.1.0-0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->ram==0.0.1)\n",
            "  Obtaining dependency information for nvidia-nvjitlink-cu12 from https://files.pythonhosted.org/packages/1e/07/bf730d44c2fe1b676ad9cc2be5f5f861eb5d153fb6951987a2d6a96379a9/nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl.metadata\n",
            "  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting ftfy (from clip@ git+https://github.com/openai/CLIP.git->ram==0.0.1)\n",
            "  Obtaining dependency information for ftfy from https://files.pythonhosted.org/packages/91/f8/dfa32d06cfcbdb76bc46e0f5d69c537de33f4cedb1a15cd4746ab45a6a26/ftfy-6.1.3-py3-none-any.whl.metadata\n",
            "  Downloading ftfy-6.1.3-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting pycocotools>=2.0.2 (from pycocoevalcap->ram==0.0.1)\n",
            "  Obtaining dependency information for pycocotools>=2.0.2 from https://files.pythonhosted.org/packages/6c/07/3c94d317ea5a35adbfe25e04a2754cfcb7ccd8ffa3a2796ab873f0bc4b7a/pycocotools-2.0.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading pycocotools-2.0.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /home/vincent/miniconda3/envs/hf/lib/python3.11/site-packages (from pycocotools>=2.0.2->pycocoevalcap->ram==0.0.1) (3.8.0)\n",
            "Collecting wcwidth<0.3.0,>=0.2.12 (from ftfy->clip@ git+https://github.com/openai/CLIP.git->ram==0.0.1)\n",
            "  Obtaining dependency information for wcwidth<0.3.0,>=0.2.12 from https://files.pythonhosted.org/packages/fd/84/fd2ba7aafacbad3c4201d395674fc6348826569da3c0937e75505ead3528/wcwidth-0.2.13-py2.py3-none-any.whl.metadata\n",
            "  Downloading wcwidth-0.2.13-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/vincent/miniconda3/envs/hf/lib/python3.11/site-packages (from jinja2->torch->ram==0.0.1) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/vincent/miniconda3/envs/hf/lib/python3.11/site-packages (from requests->transformers==4.25.1->ram==0.0.1) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/vincent/miniconda3/envs/hf/lib/python3.11/site-packages (from requests->transformers==4.25.1->ram==0.0.1) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/vincent/miniconda3/envs/hf/lib/python3.11/site-packages (from requests->transformers==4.25.1->ram==0.0.1) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/vincent/miniconda3/envs/hf/lib/python3.11/site-packages (from requests->transformers==4.25.1->ram==0.0.1) (2023.7.22)\n",
            "Collecting mpmath>=0.19 (from sympy->torch->ram==0.0.1)\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/vincent/miniconda3/envs/hf/lib/python3.11/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap->ram==0.0.1) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/vincent/miniconda3/envs/hf/lib/python3.11/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap->ram==0.0.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/vincent/miniconda3/envs/hf/lib/python3.11/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap->ram==0.0.1) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /home/vincent/miniconda3/envs/hf/lib/python3.11/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap->ram==0.0.1) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /home/vincent/miniconda3/envs/hf/lib/python3.11/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap->ram==0.0.1) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/vincent/miniconda3/envs/hf/lib/python3.11/site-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap->ram==0.0.1) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /home/vincent/miniconda3/envs/hf/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap->ram==0.0.1) (1.16.0)\n",
            "Downloading torch-2.1.2-cp311-cp311-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m422.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:08\u001b[0mm\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:07\u001b[0mm\n",
            "\u001b[?25hDownloading triton-2.1.0-0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.11.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.16.2-cp311-cp311-manylinux1_x86_64.whl (6.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading pycocotools-2.0.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (463 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m463.7/463.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
            "\u001b[?25hDownloading ftfy-6.1.3-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)\n",
            "Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: fairscale, clip\n",
            "  Building wheel for fairscale (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for fairscale: filename=fairscale-0.4.4-py3-none-any.whl size=292832 sha256=e783fee86c35ca19c98389160b774d1c87b393192ed81ce9d05cd5d2b70c131c\n",
            "  Stored in directory: /home/vincent/.cache/pip/wheels/a3/18/68/b84796fef74ea879bb05cc499235ccbd3ccf097f673420cd39\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369501 sha256=8c33228ea8f53eedf6fb0098caad56fe3d49659a750887760fc3b1446e2f36af\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-q6mzzrvs/wheels/3f/7c/a4/9b490845988bf7a4db33674d52f709f088f64392063872eb9a\n",
            "Successfully built fairscale clip\n",
            "Installing collected packages: wcwidth, tokenizers, mpmath, triton, sympy, scipy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, ftfy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, transformers, pycocotools, nvidia-cusolver-cu12, torch, pycocoevalcap, torchvision, fairscale, timm, clip, ram\n",
            "  Attempting uninstall: wcwidth\n",
            "    Found existing installation: wcwidth 0.2.6\n",
            "    Uninstalling wcwidth-0.2.6:\n",
            "      Successfully uninstalled wcwidth-0.2.6\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.14.1\n",
            "    Uninstalling tokenizers-0.14.1:\n",
            "      Successfully uninstalled tokenizers-0.14.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.34.0\n",
            "    Uninstalling transformers-4.34.0:\n",
            "      Successfully uninstalled transformers-4.34.0\n",
            "  Running setup.py develop for ram\n",
            "Successfully installed clip-1.0 fairscale-0.4.4 ftfy-6.1.3 mpmath-1.3.0 networkx-3.2.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 pycocoevalcap-1.2 pycocotools-2.0.7 ram-0.0.1 scipy-1.11.4 sympy-1.12 timm-0.4.12 tokenizers-0.13.3 torch-2.1.2 torchvision-0.16.2 transformers-4.25.1 triton-2.1.0 wcwidth-0.2.13\n"
          ]
        }
      ],
      "source": [
        "# !pip install -q -e ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drykvjvOfILL"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2p226B6fJk9",
        "outputId": "45370d71-0c34-4d13-abf2-fb86c474d485"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------\n",
            "pretrained/ram_plus_swin_large_14m.pth\n",
            "--------------\n",
            "load checkpoint from pretrained/ram_plus_swin_large_14m.pth\n",
            "vit: swin_l\n",
            "Image Tags:  armchair | blanket | lamp | carpet | couch | dog | gray | green | hassock | home | lay | living room | picture frame | pillow | plant | room | wall lamp | sit | wood floor\n"
          ]
        }
      ],
      "source": [
        "!python inference_ram_plus.py  --image images/demo/demo1.jpg --pretrained pretrained/ram_plus_swin_large_14m.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-iP72j_YfP6v"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
