{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qdrant_client\n",
    "from llama_index.vector_stores import QdrantVectorStore, ChromaVectorStore\n",
    "from llama_index.storage import StorageContext\n",
    "from llama_index import ServiceContext, VectorStoreIndex\n",
    "from llama_index.embeddings import LangchainEmbedding\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from llama_index.schema import TextNode\n",
    "import chromadb\n",
    "\n",
    "# Create a local Qdrant vector store\n",
    "client = qdrant_client.QdrantClient(path=\"play_qdrant_gemini\")\n",
    "vector_store = QdrantVectorStore(client=client, collection_name=\"collection\")\n",
    "\n",
    "# Create a local Chroma vector store\n",
    "# db = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "# chroma_collection = db.get_or_create_collection(\"quickstart\")\n",
    "# vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "\n",
    "# set OPENAI_API_KEY in your environment variables\n",
    "import os\n",
    "import openai\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = LangchainEmbedding(HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\"))\n",
    "\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    embed_model=embed_model\n",
    ")\n",
    "\n",
    "# storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "# nodes = [TextNode(text=\"HelloWorld\"), TextNode(text=\"HelloWorld\")]\n",
    "\n",
    "# index = VectorStoreIndex(\n",
    "#     nodes=nodes,\n",
    "#     storage_context=storage_context,\n",
    "#     service_context=service_context,\n",
    "# )\n",
    "\n",
    "# To store the index in memory\n",
    " \n",
    "# index.storage_context.persist(persist_dir='./check_storage')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_index import StorageContext, load_index_from_storage\n",
    "\n",
    "# # rebuild storage context\n",
    "# storage_context = StorageContext.from_defaults(persist_dir=\"./check_storage\")\n",
    "# # load index\n",
    "# index = load_index_from_storage(storage_context, service_context=service_context)\n",
    "\n",
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store,\n",
    "    service_context=service_context,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.vector_stores.types import MetadataInfo, VectorStoreInfo\n",
    "\n",
    "vector_store_info = VectorStoreInfo(\n",
    "    content_info=\"Photos\",\n",
    "    metadata_info=[\n",
    "        MetadataInfo(\n",
    "            name=\"image_file\",\n",
    "            description=\"The image file name\",\n",
    "            type=\"string\",\n",
    "        ),\n",
    "        MetadataInfo(\n",
    "            name=\"image_path\",\n",
    "            description=\"The image path\",\n",
    "            type=\"string\",\n",
    "        ),\n",
    "        MetadataInfo(\n",
    "            name=\"image_thumbnail_path\",\n",
    "            description=\"The image thumbnail path\",\n",
    "            type=\"string\",\n",
    "        ),\n",
    "        MetadataInfo(\n",
    "            name=\"image_metadata\",\n",
    "            description=\"The image metadata\",\n",
    "            type=\"object\",\n",
    "        ),\n",
    "        MetadataInfo(\n",
    "            name=\"image_is_screenshot\",\n",
    "            description=\"Whether the image is a screenshot\",\n",
    "            type=\"boolean\",\n",
    "        ),\n",
    "        MetadataInfo(\n",
    "            name=\"image_part_of_which_album\",\n",
    "            description=\"The albums the image is part of\",\n",
    "            type=\"array\",\n",
    "        ),\n",
    "        MetadataInfo(\n",
    "            name=\"image_face_ids\",\n",
    "            description=\"The face ids of the image\",\n",
    "            type=\"array\",\n",
    "        ),\n",
    "        MetadataInfo(\n",
    "            name=\"image_size\",\n",
    "            description=\"The size of the image\",\n",
    "            type=\"string\",\n",
    "        ),\n",
    "        MetadataInfo(\n",
    "            name=\"image_type\",\n",
    "            description=\"The type of the image\",\n",
    "            type=\"string\",\n",
    "        ),\n",
    "        MetadataInfo(\n",
    "            name=\"imagetag\",\n",
    "            description=\"The tags of the image\",\n",
    "            type=\"array\",\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "from llama_index.retrievers import VectorIndexAutoRetriever\n",
    "\n",
    "retriever = VectorIndexAutoRetriever(\n",
    "    index,\n",
    "    vector_store_info=vector_store_info,\n",
    "    similarity_top_k=2,\n",
    "    empty_query_top_k=10,  # if only metadata filters are specified, this is the limit\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "from typing import List\n",
    "\n",
    "def display_response(nodes: List[TextNode]):\n",
    "    \"\"\"Display response.\"\"\"\n",
    "    for node in nodes:\n",
    "        print(node.get_content(metadata_mode=\"all\"))\n",
    "        # img = Image.open(open(node.metadata[\"image_file\"], 'rb'))\n",
    "        display(Image(filename=node.metadata[\"image_file\"], width=200))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using query str: man car\n",
      "Using filters: []\n",
      "HelloWorld\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'image_file'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m nodes \u001b[38;5;241m=\u001b[39m retriever\u001b[38;5;241m.\u001b[39mretrieve(\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGive me the photos with a man and a car\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m )\n\u001b[0;32m----> 4\u001b[0m \u001b[43mdisplay_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 81\u001b[0m, in \u001b[0;36mdisplay_response\u001b[0;34m(nodes)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28mprint\u001b[39m(node\u001b[38;5;241m.\u001b[39mget_content(metadata_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# img = Image.open(open(node.metadata[\"image_file\"], 'rb'))\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m display(Image(filename\u001b[38;5;241m=\u001b[39m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage_file\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m, width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m))\n",
      "\u001b[0;31mKeyError\u001b[0m: 'image_file'"
     ]
    }
   ],
   "source": [
    "nodes = retriever.retrieve(\n",
    "    \"Give me the photos with a man and a car\"\n",
    ")\n",
    "display_response(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
